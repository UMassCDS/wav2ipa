{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77c8865",
   "metadata": {},
   "source": [
    "# TIMIT performance analysis\n",
    "This analyzes model performance on the full TIMIT corpus, with special attention to performance on vowels. There are no IPA reductions to a shared symbol set done here. These results should not be used in final presentations or results, as they include models that were actually trained on the TIMIT corpus. However, these serve as a sanity check for performance of all models on TIMIT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab68502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import ipatok\n",
    "import kaldialign\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "PALETTE = \"gist_gray\"\n",
    "sns.color_palette(PALETTE)\n",
    "font = {\"size\": 16}\n",
    "matplotlib.rc(\"font\", **font)\n",
    "# Remove the limits on the number of rows displayed in the notebook\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de47879",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLD_TRANSCRIPTIONS_CSV = Path(\"../../data/TIMIT Dataset/complete_ipa.csv\")\n",
    "\n",
    "TIMIT_EVAL_DIR = Path(\"../../data/timit_results/\")\n",
    "AGG_METRICS_CSV = TIMIT_EVAL_DIR / \"aggregate_metrics\" / \"all_models_eval.csv\"\n",
    "FB_AGG_METRICS_CSV = TIMIT_EVAL_DIR / \"aggregate_metrics\" / \"facebook_wav2vec2-espeak.csv\"\n",
    "\n",
    "DETAILED_PRED_DIR = TIMIT_EVAL_DIR / \"detailed_predictions\"\n",
    "EDIT_DIST_DIR = TIMIT_EVAL_DIR / \"edit_distances\"\n",
    "\n",
    "TIMIT_VOWELS = [\"ɑ\", \"æ\", \"ʌ\", \"ɔ\", \"ɛ\", \"ɪ\", \"i\", \"ʊ\", \"u\", \"ə\", \"ə̥\", \"ʉ\", \"ɨ\", \"ɹ̩\", \"ɚ\"]\n",
    "TIMIT_DIPHTHONGS = [\"aʊ\", \"eɪ\", \"aɪ\",  \"oʊ\", \"ɔɪ\"]\n",
    "\n",
    "DIALECT_REGIONS = {\n",
    "    \"DR1\": \"DR1: New England\",\n",
    "    \"DR2\": \"DR2: Northern\",\n",
    "    \"DR3\": \"DR3: North Midland\",\n",
    "    \"DR4\": \"DR4: South Midland\",\n",
    "    \"DR5\": \"DR5: Southern\",\n",
    "    \"DR6\": \"DR6: New York City\",\n",
    "    \"DR7\": \"DR7: Western\",\n",
    "    \"DR8\": \"DR8: Army Brat\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15357d",
   "metadata": {},
   "source": [
    "## Basic model performance comparisons\n",
    "Show performance metrics for each model on TIMIT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define and join model source description\n",
    "model_sources = [\n",
    "    (\"ginic/full_dataset_train_1_wav2vec2-large-xlsr-53-buckeye-ipa\", \"Buckeye fine-tuned on full train split\"),\n",
    "    (\"excalibur12/wav2vec2-large-lv60_phoneme-timit_english_timit-4k\", \"Lee 2025 Wav2Vec2.0 TIMIT fine-tuned\"),\n",
    "    (\"ginic/wav2vec2-large-lv60_phoneme-timit_english_timit-4k_buckeye-4k_bs32_3\", \"Lee 2025 fine-tuned again on Buckeye\"),\n",
    "    (\"openai_whisper-medium.en_to_epitran\", \"Whisper + Epitran\"),\n",
    "    (\"facebook/wav2vec2-lv-60-espeak-cv-ft\", \"facebook/wav2vec2-lv-60-espeak-cv-ft\"),\n",
    "    (\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\", \"facebook/wav2vec2-xlsr-53-espeak-cv-ft\"),\n",
    "    (\"allosaurus_eng2102_eng\", \"Allosaurus English\"),\n",
    "    (\"ctaguchi/wav2vec2-large-xlsr-japlmthufielta-ipa1000-ns\", \"Taguchi et al. 2023\"),\n",
    "    # Intentionally omitting Whisper large - let's just keep the best in each category\n",
    "    (\"openai_whisper-large-v3-turbo_to_epitran\", \"Whisper + Epitran\"),\n",
    "\n",
    "]\n",
    "\n",
    "hue_order = [t[1] for t in model_sources]\n",
    "\n",
    "model_sources_df = pd.DataFrame(model_sources, columns=[\"model\", \"Model source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aggregate performance data\n",
    "aggregate_perf_df = pd.concat([pd.read_csv(AGG_METRICS_CSV), pd.read_csv(FB_AGG_METRICS_CSV)])\n",
    "aggregate_perf_df = pd.merge(aggregate_perf_df, model_sources_df, on=\"model\").sort_values(by=\"mean_phone_error_rate\")\n",
    "\n",
    "display(aggregate_perf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "g = sns.barplot(\n",
    "    data=aggregate_perf_df, y=\"Model source\", x=\"mean_phone_error_rate\", hue=\"Model source\", palette=PALETTE, hue_order=hue_order\n",
    ")\n",
    "g.set_title(\"Comparison of Phone Error Rates: TIMIT\")\n",
    "g.set_xlabel(\"Average Phone Error Rate\\non TIMIT Corpus\")\n",
    "g.set_xlim((0,1))\n",
    "\n",
    "for bar in g.containers:\n",
    "    g.bar_label(bar, fmt=\"%.2f\", padding=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "g = sns.barplot(\n",
    "    data=aggregate_perf_df,\n",
    "    y=\"Model source\",\n",
    "    x=\"mean_phone_feature_error_rate\",\n",
    "    hue=\"Model source\",\n",
    "    palette=PALETTE,\n",
    "    hue_order=hue_order,\n",
    ")\n",
    "g.set_title(\"Comparison of Phone Feature Error Rates: TIMIT\")\n",
    "g.set_xlabel(\"Average Phone Feature Error Rate\\non TIMIT Corpus\")\n",
    "\n",
    "g.set_xlim((0, 7))\n",
    "\n",
    "for bar in g.containers:\n",
    "    g.bar_label(bar, fmt=\"%.2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look specifically at substitution errors\n",
    "substitution_dfs = []\n",
    "for (model, _) in model_sources:\n",
    "    file_prefix = model.replace(\"/\", \"_\")\n",
    "    edit_dist_path = EDIT_DIST_DIR / f\"{file_prefix}_substitutions.csv\"\n",
    "    edit_dist_df = pd.read_csv(edit_dist_path)\n",
    "    edit_dist_df[\"model\"] = model\n",
    "    substitution_dfs.append(edit_dist_df)\n",
    "\n",
    "full_substitution_df = pd.concat(substitution_dfs)\n",
    "print(full_substitution_df.shape)\n",
    "display(full_substitution_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d249643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total substitution errors for each model\n",
    "subs_count_df = full_substitution_df.groupby(\"model\")[\"total_substitutions\"].sum().reset_index().sort_values(by=\"total_substitutions\", ascending=True)\n",
    "subs_count_df = pd.merge(subs_count_df, model_sources_df, on=\"model\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "g = sns.barplot(\n",
    "    data=subs_count_df,\n",
    "    y=\"Model source\",\n",
    "    x=\"total_substitutions\",\n",
    "    hue=\"Model source\",\n",
    "    palette=PALETTE,\n",
    "    hue_order=hue_order,\n",
    ")\n",
    "g.set_title(\"Comparison of Total Substitutions Errors: TIMIT\")\n",
    "g.set_xlabel(\"Total Substitution Errors\\non TIMIT Corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d6997",
   "metadata": {},
   "source": [
    "# Dialect Region Performance Plots\n",
    "This creates bar charts showing performance by dialect. Since the groupby and averaging was already done, we just need to read in the data and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in predictions and extract dialect region\n",
    "detailed_results_dfs = []\n",
    "for model, label in model_sources:\n",
    "    clean_model_name = model.replace(\"/\", \"_\")\n",
    "    tmp_df = pd.read_csv(DETAILED_PRED_DIR / f\"{clean_model_name}_detailed_predictions.csv\")\n",
    "    tmp_df[\"model_name\"] = model\n",
    "    tmp_df[\"Model source\"] = label\n",
    "    detailed_results_dfs.append(tmp_df)\n",
    "\n",
    "detailed_preds_df = pd.concat(detailed_results_dfs)\n",
    "detailed_preds_df[\"dialect\"] = detailed_preds_df[\"filename\"].apply(lambda x: x.split(\"/\")[2].upper())\n",
    "display(detailed_preds_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show performance by dialect region\n",
    "dialect_df = detailed_preds_df.groupby([\"model_name\", \"Model source\", \"dialect\"])[\"phone_error_rates\"].mean().reset_index()\n",
    "display(dialect_df.head())\n",
    "dialect_df = dialect_df.merge(pd.DataFrame(DIALECT_REGIONS.items(), columns=[\"dialect\", \"Dialect Region\"]), on=\"dialect\")\n",
    "dialect_df =  dialect_df.sort_values(by=[\"Dialect Region\", \"phone_error_rates\"], ascending=[True, True])\n",
    "display(dialect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(dialect_df, col=\"Dialect Region\", col_wrap=4, height=4, aspect=0.75)\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.map_dataframe(sns.barplot, y=\"phone_error_rates\", hue=\"Model source\", palette=PALETTE, hue_order = hue_order)\n",
    "g.add_legend(title=\"Model source\")\n",
    "g.set_ylabels(\"Average Phone Error Rate\")\n",
    "g.fig.suptitle(\"Models' Average Phone Error Rates by Dialect Region\", fontsize=24, y=1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialect performance for just our model\n",
    "our_model_dialect_df = dialect_df[dialect_df[\"Model source\"] == \"Our AutoIPA: fine-tuned on full train split\"]\n",
    "g = sns.barplot(data=our_model_dialect_df, y=\"Dialect Region\", x=\"phone_error_rates\", hue=\"Dialect Region\", palette=PALETTE)\n",
    "g.set_xlabel(\"Average Phone Error Rate\")\n",
    "g.set_xlim((0,0.5))\n",
    "g.set(title=\"Our AutoIPA's TIMIT Performance by Dialect Region\")\n",
    "for bar in g.containers:\n",
    "    g.bar_label(bar, fmt=\"%.2f\", padding=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b303a",
   "metadata": {},
   "source": [
    "# Vowel Error Rate Analysis\n",
    "How many instances of each vowel in the vocabulary are we getting wrong? \n",
    "$$ error\\_rate(v) = \\frac{count\\_substitutions\\_of(v) + count\\_deletions(v)}{total\\_count(v)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_transcription_df = pd.read_csv(GOLD_TRANSCRIPTIONS_CSV)\n",
    "gold_transcription_df[\"filename\"] = gold_transcription_df[\"audio_filename\"].str.lower()\n",
    "gold_transcription_df[\"ipa_transcription\"] = gold_transcription_df[\"ipa_transcription\"].str.replace(\"ɝ\", \"ɹ̩\")\n",
    "vowel_counts = Counter()\n",
    "for vowel in TIMIT_VOWELS + TIMIT_DIPHTHONGS:\n",
    "    vowel_counts[vowel] += gold_transcription_df[\"ipa_transcription\"].apply(lambda x: x.split().count(vowel)).sum()\n",
    "\n",
    "vowel_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5236dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple bar chart of vowel counts\n",
    "plot_vowels, plot_counts = zip(*vowel_counts.most_common())\n",
    "g = sns.barplot(y=plot_vowels, x=plot_counts, palette=\"colorblind\")\n",
    "g.set_xlim(0, 13500)\n",
    "g.set_xlabel(\"count\")\n",
    "g.set(title=\"Counts of TIMIT Vowel Occurrences\")\n",
    "for bar in g.containers:\n",
    "    g.bar_label(bar, fontsize='small')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d32bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = \"***\"\n",
    "def tally_edit_distance_errors(references, predictions):\n",
    "    \"\"\"Counts up edit distances from lists of already tokenized references and predictions.\"\"\"\n",
    "    subs = Counter()\n",
    "    insertions = Counter()\n",
    "    deletions = Counter()\n",
    "    for ref_tokens, pred_tokens in zip(references, predictions):\n",
    "        aligned_pairs = kaldialign.align(ref_tokens, pred_tokens, EPS)\n",
    "\n",
    "        for r, p in aligned_pairs:\n",
    "            if r == EPS:\n",
    "                insertions[p] += 1\n",
    "            elif p == EPS:\n",
    "                deletions[r] += 1\n",
    "            elif r != p:\n",
    "                subs[(r, p)] += 1\n",
    "\n",
    "    return subs, deletions, insertions\n",
    "\n",
    "def diphthong_merge(t1, t2):\n",
    "    \"\"\"For merge detected diphthongs in predicted output when using ipatok.tokenise\"\"\"\n",
    "    if t1+t2 in TIMIT_DIPHTHONGS:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a81f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-do edit distance calculations with better tokenization, specifically turning\n",
    "# on diphthong tokenization\n",
    "our_model_detailed_preds_df = pd.read_csv(DETAILED_PRED_DIR / \"ginic_full_dataset_train_1_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\").drop(columns=[\"substitutions\", \"insertions\", \"deletions\"])\n",
    "full_edit_distance_analysis_df = pd.merge(gold_transcription_df, our_model_detailed_preds_df, on=\"filename\")\n",
    "\n",
    "full_edit_distance_analysis_df[\"ipa_tokens\"] = full_edit_distance_analysis_df[\"ipa_transcription\"].str.split()\n",
    "full_edit_distance_analysis_df[\"predicted_ipa_tokens\"] = full_edit_distance_analysis_df[\"prediction\"].apply(lambda x: ipatok.tokenise(x, diphthongs=True, merge=diphthong_merge))\n",
    "print(full_edit_distance_analysis_df[\"ipa_tokens\"][:10])\n",
    "print(full_edit_distance_analysis_df[\"predicted_ipa_tokens\"][:10])\n",
    "display(full_edit_distance_analysis_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_counter, del_counter, inserts_counter = tally_edit_distance_errors(full_edit_distance_analysis_df[\"ipa_tokens\"], full_edit_distance_analysis_df[\"predicted_ipa_tokens\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb465936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subs and deletions in good format for analysis\n",
    "detailed_error_counts = defaultdict(Counter)\n",
    "subs_counts = Counter()\n",
    "for (sub_tuple, count) in sub_counter.items():\n",
    "    subs_counts[sub_tuple[0]] += count\n",
    "    detailed_error_counts[sub_tuple[0]][sub_tuple[1]] += count\n",
    "\n",
    "print(\"Substitution Counts:\", subs_counts)\n",
    "\n",
    "for (deleted, count) in del_counter.items():\n",
    "    detailed_error_counts[deleted][\"<deleted>\"] += count\n",
    "\n",
    "print(\"Detailed Error Counts:\", detailed_error_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc57b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute vowel error rates\n",
    "vowel_error_rates = {}\n",
    "for v in TIMIT_VOWELS + TIMIT_DIPHTHONGS:\n",
    "    subs_count = subs_counts[v]\n",
    "    dels_count = del_counter[v]\n",
    "    ver = (subs_count + dels_count)/ (vowel_counts[v])\n",
    "    vowel_error_rates[v] = ver\n",
    "\n",
    "ver_df = pd.DataFrame(vowel_error_rates.items(), columns=[\"Vowel\", \"Vowel Error Rate\"]). sort_values(by=\"Vowel Error Rate\", ascending=False)\n",
    "error_ordering = ver_df[ver_df[\"Vowel Error Rate\"] > 0][\"Vowel\"].tolist()\n",
    "print(\"In descending frequency of errors:\", error_ordering)\n",
    "\n",
    "display(ver_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "sns.heatmap(\n",
    "    ver_df.sort_values(by=\"Vowel Error Rate\", ascending=False).set_index(\"Vowel\"),\n",
    "    cmap=\"rainbow\",\n",
    "    # cmap=\"spring_r\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    yticklabels=True,\n",
    "    # linewidths=1,\n",
    ")\n",
    "plt.title(\"AutoIPA TIMIT Vowel Error Rates\\n(Descending worst to best)\")\n",
    "# plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_vowels = ver_df[ver_df[\"Vowel Error Rate\"] > 0.0][\"Vowel\"].tolist()\n",
    "print(interesting_vowels)\n",
    "\n",
    "\n",
    "interesting_errors = []\n",
    "for v in interesting_vowels:\n",
    "    for error, count in detailed_error_counts[v].items():\n",
    "        interesting_errors.append((v, error, count))\n",
    "\n",
    "interesting_errors_df = pd.DataFrame(interesting_errors, columns=[\"Vowel\", \"Error\", \"Count\"])\n",
    "interesting_errors_df[\"Ratio of Vowel's Errors\"] = interesting_errors_df.groupby(\"Vowel\", group_keys=False)[\"Count\"].apply(lambda x: x / x.sum())\n",
    "display(interesting_errors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab top ten errors for each vowel\n",
    "top_errors_df = interesting_errors_df.groupby(\"Vowel\").apply(lambda x: x.nlargest(5, \"Count\")).reset_index(drop=True)\n",
    "top_errors_df[\"Vowel\"] = pd.Categorical(top_errors_df[\"Vowel\"], categories=error_ordering, ordered=True)\n",
    "top_errors_df = top_errors_df.sort_values(by=[\"Vowel\", \"Count\"], ascending=[True, False])\n",
    "display(top_errors_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_errors = [\"ɨ\", \"ʉ\", \"ə̥\", \"ə\", \"ɚ\"]\n",
    "\n",
    "convention_errors_df = top_errors_df[top_errors_df[\"Vowel\"].isin(convention_errors)]\n",
    "convention_errors_df[\"Vowel\"] = pd.Categorical(convention_errors_df[\"Vowel\"], categories=convention_errors, ordered=True)\n",
    "g = sns.FacetGrid(convention_errors_df, col=\"Vowel\", col_wrap=3, sharey=False, xlim=(0, 1), aspect=1.25)\n",
    "g.map_dataframe(sns.barplot, x=\"Ratio of Vowel's Errors\", y=\"Error\", orient=\"h\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_ylabels(\"Error or\\nSubstitution\")\n",
    "g.set_xlabels(\"As ratio of total errors\\naffecting the vowel\")\n",
    "g.fig.suptitle(\"Top 5 errors for vowels Wav2IPA always incorrectly transcribes\", fontsize=24, y=1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e238e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_convention_errors = [v for v in interesting_vowels if v not in convention_errors]\n",
    "print(not_convention_errors)\n",
    "not_convention_errors_df = top_errors_df[top_errors_df[\"Vowel\"].isin(not_convention_errors)]\n",
    "not_convention_errors_df[\"Vowel\"] = pd.Categorical(\n",
    "not_convention_errors_df[\"Vowel\"], categories=not_convention_errors, ordered=True\n",
    ")\n",
    "display(not_convention_errors_df.head(20))\n",
    "\n",
    "g = sns.FacetGrid(not_convention_errors_df, col=\"Vowel\", col_wrap=5, sharey=False, aspect=1.25, xlim=(0, 1))\n",
    "g.map_dataframe(sns.barplot, x=\"Ratio of Vowel's Errors\", y=\"Error\", orient=\"h\")\n",
    "g.set_titles(col_template=\"{col_name}\", fontsize=20)\n",
    "g.set_ylabels(\"Error or\\nSubstitution\")\n",
    "g.set_xlabels(\"As ratio of total errors\\naffecting the vowel\")\n",
    "g.fig.suptitle(\"Remaining TIMIT Vowels: Top 5 Wav2IPA Errors for each vowel\", fontsize=24, y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbb9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
